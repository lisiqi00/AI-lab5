{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 指定GPU来跑代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 获取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 获取所有文本数据、图片数据和标签数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 所有文本数据、图片数据、图片id数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "image_data={} #所有图片数据\n",
    "text_data={} #所有文本数据\n",
    "\n",
    "for i in range(1,5130):\n",
    "    img_path='data/'+str(i)+'.jpg'\n",
    "    text_path='data/'+str(i)+'.txt'\n",
    "    if os.path.exists(img_path) and os.path.exists(text_path):\n",
    "        #读图片数据\n",
    "        img=Image.open(img_path).resize((224,224))\n",
    "        img_array=np.array(img)\n",
    "        image_data[i]=img_array\n",
    "        #读文本数据\n",
    "        with open(text_path,'r',encoding='utf-8',errors='replace') as file:\n",
    "            text_str=file.read()\n",
    "            text_data[i]=text_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#按key序排序\n",
    "sorted_image_data=dict(sorted(image_data.items(), key=lambda x: x[0]))\n",
    "sorted_text_data=dict(sorted(text_data.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[116  65  22]\n",
      "  [118  63  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [213 141  66]\n",
      "  [220 147  70]\n",
      "  [211 138  61]]\n",
      "\n",
      " [[117  66  23]\n",
      "  [119  64  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [218 145  70]\n",
      "  [226 152  75]\n",
      "  [219 144  67]]\n",
      "\n",
      " [[118  67  23]\n",
      "  [119  65  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [225 149  74]\n",
      "  [237 160  84]\n",
      "  [231 154  78]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  7   2   5]\n",
      "  [  9   3   1]\n",
      "  [ 20  11   2]\n",
      "  ...\n",
      "  [100  72  62]\n",
      "  [114  90  81]\n",
      "  [104  84  73]]\n",
      "\n",
      " [[  6   2   4]\n",
      "  [  9   3   1]\n",
      "  [ 19  11   2]\n",
      "  ...\n",
      "  [ 91  63  53]\n",
      "  [ 88  65  54]\n",
      "  [ 73  54  43]]\n",
      "\n",
      " [[  5   0   3]\n",
      "  [ 10   3   1]\n",
      "  [ 19  10   1]\n",
      "  ...\n",
      "  [ 84  56  46]\n",
      "  [ 87  63  53]\n",
      "  [ 63  44  33]]]\n",
      "[[[116  65  22]\n",
      "  [118  63  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [213 141  66]\n",
      "  [220 147  70]\n",
      "  [211 138  61]]\n",
      "\n",
      " [[117  66  23]\n",
      "  [119  64  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [218 145  70]\n",
      "  [226 152  75]\n",
      "  [219 144  67]]\n",
      "\n",
      " [[118  67  23]\n",
      "  [119  65  21]\n",
      "  [124  64  21]\n",
      "  ...\n",
      "  [225 149  74]\n",
      "  [237 160  84]\n",
      "  [231 154  78]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  7   2   5]\n",
      "  [  9   3   1]\n",
      "  [ 20  11   2]\n",
      "  ...\n",
      "  [100  72  62]\n",
      "  [114  90  81]\n",
      "  [104  84  73]]\n",
      "\n",
      " [[  6   2   4]\n",
      "  [  9   3   1]\n",
      "  [ 19  11   2]\n",
      "  ...\n",
      "  [ 91  63  53]\n",
      "  [ 88  65  54]\n",
      "  [ 73  54  43]]\n",
      "\n",
      " [[  5   0   3]\n",
      "  [ 10   3   1]\n",
      "  [ 19  10   1]\n",
      "  ...\n",
      "  [ 84  56  46]\n",
      "  [ 87  63  53]\n",
      "  [ 63  44  33]]]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_image_data[1])\n",
    "print(sorted_image_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 根据guid获取到对应的label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data=dict()\n",
    "with open('train.txt','r',encoding='utf-8') as label_file:\n",
    "    next(label_file) #跳过第一行（标题行）\n",
    "    for line in label_file:\n",
    "        key, value = line.strip().split(',')\n",
    "        label_data[int(key)]=value\n",
    "\n",
    "#将label_data按照guid排序\n",
    "sorted_label_data = dict(sorted(label_data.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_guid=list()\n",
    "with open('test_without_label.txt','r',encoding='utf-8') as test_id_file:\n",
    "    next(test_id_file)\n",
    "    for line in test_id_file:\n",
    "        key,value=line.strip().split(',')\n",
    "        test_guid.append(int(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将文本数据进行word2vec向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#文本数据的预处理\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "sorted_pure_text_data=dict() #存储每个句子分词后的结果\n",
    "#文本数据的预处理\n",
    "for key in sorted_text_data:\n",
    "    # print(sorted_text_data[key])\n",
    "    #正则表达式匹配非字母、数字和空格的字符并删除\n",
    "    pattern = r'[^a-zA-Z0-9\\s]'\n",
    "    cleaned_text = re.sub(pattern, '', sorted_text_data[key])\n",
    "    #去除停止词，并都转化为小写字母\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    tokens=cleaned_text.split() #分词\n",
    "    filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words]  # 去除停止词\n",
    "    # tokens=sorted_text_data[key].split() #分词\n",
    "    # filtered_tokens = [word.lower() for word in tokens]  # 去除停止词\n",
    "    sorted_pure_text_data[key]=filtered_tokens\n",
    "    # print(sorted_pure_text_data[key])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feel', 'today', 'legday', 'jelly', 'aching', 'gym']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sorted_pure_text_data.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec对文本数据进行词向量化\n",
    "from gensim.models import Word2Vec\n",
    "w2v_model=Word2Vec(list(sorted_pure_text_data.values()),min_count=5,vector_size=50)\n",
    "word_vec_matrix=w2v_model.wv #词向量矩阵\n",
    "#向词向量矩阵中添加<pad>和<unk>对应的词向量\n",
    "#每个词对应的词向量的维度\n",
    "embedding_dim=w2v_model.vector_size\n",
    "unk_vector=np.random.uniform(-1,1,embedding_dim)\n",
    "pad_vector=np.zeros(embedding_dim)\n",
    "#添加新的词向量\n",
    "word_vec_matrix.add_vectors(keys=['<unk>','<pad>'], weights=[unk_vector, pad_vector])\n",
    "#生成的词向量矩阵的词典中含有的词的List\n",
    "w2v_word_vocab=word_vec_matrix.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到词到id，id到词的映射词典\n",
    "word2index=dict()\n",
    "for i in range(len(w2v_word_vocab)):\n",
    "    word2index[w2v_word_vocab[i]]=i\n",
    "index2word=dict()\n",
    "for i in range(len(word2index.items())):\n",
    "    index2word[list(word2index.values())[i]]=list(word2index.keys())[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集，验证集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "val_idx=list()\n",
    "train_idx=list()\n",
    "\n",
    "val_idx=random.sample(list(sorted_label_data.keys()),int(len(sorted_label_data.keys())*0.2))\n",
    "for idx in list(sorted_label_data.keys()):\n",
    "    if idx not in val_idx:\n",
    "        train_idx.append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造验证集\n",
    "val_text=list()\n",
    "val_image=list()\n",
    "val_label_target=list()\n",
    "val_guid=sorted(val_idx)\n",
    "for val_idx in val_guid:\n",
    "    val_text.append(sorted_pure_text_data[val_idx]) #验证集文本数据\n",
    "    val_image.append(sorted_image_data[val_idx]) #对应的验证集图像数据\n",
    "    val_label_target.append(sorted_label_data[val_idx])\n",
    "\n",
    "#构造训练集\n",
    "train_text=list()\n",
    "train_image=list()\n",
    "train_label=list()\n",
    "train_guid=sorted(train_idx)\n",
    "for train_idx in train_guid:\n",
    "    train_text.append(sorted_pure_text_data[train_idx])\n",
    "    train_image.append(sorted_image_data[train_idx])\n",
    "    train_label.append(sorted_label_data[train_idx])\n",
    "\n",
    "#构造测试集\n",
    "test_text=list()\n",
    "test_image=list()\n",
    "for test_idx in test_guid:\n",
    "    test_text.append(sorted_pure_text_data[test_idx])\n",
    "    test_image.append(sorted_image_data[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于文本数据，构建LSTM模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 对文本数据的预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将词转换成索引编码\n",
    "train_text2id=list()\n",
    "for sentence in train_text:\n",
    "    sentence_id_list=list()\n",
    "    for word in sentence:\n",
    "        if word not in w2v_word_vocab:\n",
    "            word='<unk>'\n",
    "        text2id=word2index[word]\n",
    "        sentence_id_list.append(text2id)\n",
    "    train_text2id.append(sentence_id_list)\n",
    "\n",
    "val_text2id=list()\n",
    "for sentence in val_text:\n",
    "    sentence_id_list=list()\n",
    "    for word in sentence:\n",
    "        if word not in w2v_word_vocab:\n",
    "            word='<unk>'\n",
    "        text2id=word2index[word]\n",
    "        sentence_id_list.append(text2id)\n",
    "    val_text2id.append(sentence_id_list)\n",
    "\n",
    "test_text2id=list()\n",
    "for sentence in test_text:\n",
    "    sentence_id_list=list()\n",
    "    for word in sentence:\n",
    "        if word not in w2v_word_vocab:\n",
    "            word='<unk>'\n",
    "        text2id=word2index[word]\n",
    "        sentence_id_list.append(text2id)\n",
    "    test_text2id.append(sentence_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "#获取句子的最大长度\n",
    "max_length=-1\n",
    "for i in range(len(list(sorted_pure_text_data.values()))):\n",
    "    if len(list(sorted_pure_text_data.values())[i])>=max_length:\n",
    "        max_length=len(list(sorted_pure_text_data.values())[i])\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将句子的长度都补到最长\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_text_pad=pad_sequences(train_text2id,maxlen=max_length,padding='post',value=word2index['<pad>'])\n",
    "val_text_pad=pad_sequences(val_text2id,maxlen=max_length,padding='post',value=word2index['<pad>'])\n",
    "test_text_pad=pad_sequences(test_text2id,maxlen=max_length,padding='post',value=word2index['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  57    9 1527 1527  415  847 1528 1528 1528 1528 1528 1528 1528 1528\n",
      " 1528 1528 1528 1528 1528 1528 1528 1528]\n"
     ]
    }
   ],
   "source": [
    "print(train_text_pad[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理标签label\n",
    "from keras.utils import to_categorical\n",
    "# 将情感标签转换为数字标签\n",
    "labels=['positive','negative','neutral']\n",
    "label_to_index = {'positive': 0, 'negative': 1, 'neutral': 2}\n",
    "index_to_label = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
    "\n",
    "train_label_idx = np.array([label_to_index[label] for label in train_label])\n",
    "val_label_target_idx = np.array([label_to_index[label] for label in val_label_target])\n",
    "#将标签进行独热编码\n",
    "train_label_one_hot = to_categorical(train_label_idx)\n",
    "val_label_one_hot = to_categorical(val_label_target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造对于文本数据用于情感分类的LSTM框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 22:20:38.483824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-14 22:20:39.129944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:e1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "#设计模型结构\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout,Input\n",
    "\n",
    "text_input=Input(shape=(max_length,))\n",
    "text_embed=Embedding(input_dim=len(w2v_word_vocab),output_dim=embedding_dim,weights=[word_vec_matrix.vectors],trainable=False)(text_input)\n",
    "text_features=LSTM(units=128)(text_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构造用于对图片数据进行建模的VGGNet_19神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Input, Flatten, Dense, Concatenate\n",
    "from keras.models import Model\n",
    "#对图像数据进行预处理\n",
    "#归一化\n",
    "# train_image=train_image.reshape(train_image.shape[0],224,224,3)\n",
    "train_image=np.array(train_image)/255.0\n",
    "val_image=np.array(val_image)/255.0\n",
    "test_image=np.array(test_image)/255.0\n",
    "#构建模型\n",
    "base_model = VGG19(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "image_input = Input(shape=(224, 224,3))\n",
    "image_features = base_model(image_input)\n",
    "image_features = Flatten()(image_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建多模态融合模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 22)]         0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 22, 50)       76450       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " vgg19 (Functional)             (None, 7, 7, 512)    20024384    ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 128)          91648       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 25088)        0           ['vgg19[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 25216)        0           ['lstm[0][0]',                   \n",
      "                                                                  'flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            75651       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,268,133\n",
      "Trainable params: 20,191,683\n",
      "Non-trainable params: 76,450\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#融合文本和图像特征\n",
    "combined_features = Concatenate()([text_features, image_features])\n",
    "predictions = Dense(3, activation='softmax')(combined_features)\n",
    "#构建多模态融合模型\n",
    "model = Model(inputs=[text_input, image_input], outputs=predictions)\n",
    "#编译模型\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练集上训练，并在验证集上进行验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 22:20:49.617429: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
      "2023-07-14 22:20:51.972256: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 22s 152ms/step - loss: 7.0162 - accuracy: 0.5684 - val_loss: 0.9180 - val_accuracy: 0.6050\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 15s 149ms/step - loss: 0.9039 - accuracy: 0.5950 - val_loss: 0.8966 - val_accuracy: 0.6050\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.9047 - accuracy: 0.5950 - val_loss: 0.9004 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.9024 - accuracy: 0.5950 - val_loss: 0.9017 - val_accuracy: 0.6050\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.9022 - accuracy: 0.5947 - val_loss: 0.8902 - val_accuracy: 0.6050\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8975 - accuracy: 0.5950 - val_loss: 0.8935 - val_accuracy: 0.6050\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 14s 143ms/step - loss: 0.8964 - accuracy: 0.5950 - val_loss: 0.8876 - val_accuracy: 0.6050\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.8934 - accuracy: 0.5950 - val_loss: 0.8912 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8960 - accuracy: 0.5947 - val_loss: 0.8895 - val_accuracy: 0.6050\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 14s 140ms/step - loss: 0.8938 - accuracy: 0.5959 - val_loss: 0.8954 - val_accuracy: 0.6062\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f69a07d90d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[train_text_pad,train_image],y=train_label_one_hot,epochs=10,batch_size=32,validation_data=([val_text_pad,val_image],val_label_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 85ms/step\n",
      "Sample 1: Predicted Label = positive\n",
      "Sample 2: Predicted Label = positive\n",
      "Sample 3: Predicted Label = positive\n",
      "Sample 4: Predicted Label = positive\n",
      "Sample 5: Predicted Label = positive\n",
      "Sample 6: Predicted Label = positive\n",
      "Sample 7: Predicted Label = positive\n",
      "Sample 8: Predicted Label = positive\n",
      "Sample 9: Predicted Label = positive\n",
      "Sample 10: Predicted Label = positive\n",
      "Sample 11: Predicted Label = positive\n",
      "Sample 12: Predicted Label = positive\n",
      "Sample 13: Predicted Label = positive\n",
      "Sample 14: Predicted Label = positive\n",
      "Sample 15: Predicted Label = positive\n",
      "Sample 16: Predicted Label = positive\n",
      "Sample 17: Predicted Label = positive\n",
      "Sample 18: Predicted Label = positive\n",
      "Sample 19: Predicted Label = positive\n",
      "Sample 20: Predicted Label = positive\n",
      "Sample 21: Predicted Label = positive\n",
      "Sample 22: Predicted Label = positive\n",
      "Sample 23: Predicted Label = positive\n",
      "Sample 24: Predicted Label = positive\n",
      "Sample 25: Predicted Label = positive\n",
      "Sample 26: Predicted Label = positive\n",
      "Sample 27: Predicted Label = positive\n",
      "Sample 28: Predicted Label = positive\n",
      "Sample 29: Predicted Label = positive\n",
      "Sample 30: Predicted Label = positive\n",
      "Sample 31: Predicted Label = positive\n",
      "Sample 32: Predicted Label = positive\n",
      "Sample 33: Predicted Label = positive\n",
      "Sample 34: Predicted Label = positive\n",
      "Sample 35: Predicted Label = positive\n",
      "Sample 36: Predicted Label = positive\n",
      "Sample 37: Predicted Label = positive\n",
      "Sample 38: Predicted Label = positive\n",
      "Sample 39: Predicted Label = positive\n",
      "Sample 40: Predicted Label = positive\n",
      "Sample 41: Predicted Label = positive\n",
      "Sample 42: Predicted Label = positive\n",
      "Sample 43: Predicted Label = positive\n",
      "Sample 44: Predicted Label = positive\n",
      "Sample 45: Predicted Label = positive\n",
      "Sample 46: Predicted Label = positive\n",
      "Sample 47: Predicted Label = positive\n",
      "Sample 48: Predicted Label = positive\n",
      "Sample 49: Predicted Label = positive\n",
      "Sample 50: Predicted Label = positive\n",
      "Sample 51: Predicted Label = positive\n",
      "Sample 52: Predicted Label = positive\n",
      "Sample 53: Predicted Label = positive\n",
      "Sample 54: Predicted Label = positive\n",
      "Sample 55: Predicted Label = positive\n",
      "Sample 56: Predicted Label = positive\n",
      "Sample 57: Predicted Label = positive\n",
      "Sample 58: Predicted Label = positive\n",
      "Sample 59: Predicted Label = positive\n",
      "Sample 60: Predicted Label = positive\n",
      "Sample 61: Predicted Label = positive\n",
      "Sample 62: Predicted Label = positive\n",
      "Sample 63: Predicted Label = positive\n",
      "Sample 64: Predicted Label = positive\n",
      "Sample 65: Predicted Label = positive\n",
      "Sample 66: Predicted Label = positive\n",
      "Sample 67: Predicted Label = positive\n",
      "Sample 68: Predicted Label = positive\n",
      "Sample 69: Predicted Label = positive\n",
      "Sample 70: Predicted Label = positive\n",
      "Sample 71: Predicted Label = neutral\n",
      "Sample 72: Predicted Label = positive\n",
      "Sample 73: Predicted Label = positive\n",
      "Sample 74: Predicted Label = positive\n",
      "Sample 75: Predicted Label = positive\n",
      "Sample 76: Predicted Label = positive\n",
      "Sample 77: Predicted Label = positive\n",
      "Sample 78: Predicted Label = positive\n",
      "Sample 79: Predicted Label = positive\n",
      "Sample 80: Predicted Label = positive\n",
      "Sample 81: Predicted Label = positive\n",
      "Sample 82: Predicted Label = positive\n",
      "Sample 83: Predicted Label = positive\n",
      "Sample 84: Predicted Label = positive\n",
      "Sample 85: Predicted Label = positive\n",
      "Sample 86: Predicted Label = positive\n",
      "Sample 87: Predicted Label = positive\n",
      "Sample 88: Predicted Label = positive\n",
      "Sample 89: Predicted Label = positive\n",
      "Sample 90: Predicted Label = positive\n",
      "Sample 91: Predicted Label = positive\n",
      "Sample 92: Predicted Label = positive\n",
      "Sample 93: Predicted Label = positive\n",
      "Sample 94: Predicted Label = positive\n",
      "Sample 95: Predicted Label = positive\n",
      "Sample 96: Predicted Label = positive\n",
      "Sample 97: Predicted Label = positive\n",
      "Sample 98: Predicted Label = positive\n",
      "Sample 99: Predicted Label = positive\n",
      "Sample 100: Predicted Label = positive\n",
      "Sample 101: Predicted Label = positive\n",
      "Sample 102: Predicted Label = positive\n",
      "Sample 103: Predicted Label = positive\n",
      "Sample 104: Predicted Label = positive\n",
      "Sample 105: Predicted Label = positive\n",
      "Sample 106: Predicted Label = positive\n",
      "Sample 107: Predicted Label = positive\n",
      "Sample 108: Predicted Label = positive\n",
      "Sample 109: Predicted Label = positive\n",
      "Sample 110: Predicted Label = positive\n",
      "Sample 111: Predicted Label = positive\n",
      "Sample 112: Predicted Label = positive\n",
      "Sample 113: Predicted Label = positive\n",
      "Sample 114: Predicted Label = positive\n",
      "Sample 115: Predicted Label = positive\n",
      "Sample 116: Predicted Label = positive\n",
      "Sample 117: Predicted Label = positive\n",
      "Sample 118: Predicted Label = positive\n",
      "Sample 119: Predicted Label = positive\n",
      "Sample 120: Predicted Label = positive\n",
      "Sample 121: Predicted Label = positive\n",
      "Sample 122: Predicted Label = positive\n",
      "Sample 123: Predicted Label = positive\n",
      "Sample 124: Predicted Label = positive\n",
      "Sample 125: Predicted Label = positive\n",
      "Sample 126: Predicted Label = positive\n",
      "Sample 127: Predicted Label = positive\n",
      "Sample 128: Predicted Label = positive\n",
      "Sample 129: Predicted Label = positive\n",
      "Sample 130: Predicted Label = positive\n",
      "Sample 131: Predicted Label = positive\n",
      "Sample 132: Predicted Label = positive\n",
      "Sample 133: Predicted Label = positive\n",
      "Sample 134: Predicted Label = positive\n",
      "Sample 135: Predicted Label = positive\n",
      "Sample 136: Predicted Label = positive\n",
      "Sample 137: Predicted Label = positive\n",
      "Sample 138: Predicted Label = positive\n",
      "Sample 139: Predicted Label = positive\n",
      "Sample 140: Predicted Label = positive\n",
      "Sample 141: Predicted Label = positive\n",
      "Sample 142: Predicted Label = positive\n",
      "Sample 143: Predicted Label = positive\n",
      "Sample 144: Predicted Label = positive\n",
      "Sample 145: Predicted Label = positive\n",
      "Sample 146: Predicted Label = positive\n",
      "Sample 147: Predicted Label = positive\n",
      "Sample 148: Predicted Label = positive\n",
      "Sample 149: Predicted Label = neutral\n",
      "Sample 150: Predicted Label = positive\n",
      "Sample 151: Predicted Label = positive\n",
      "Sample 152: Predicted Label = positive\n",
      "Sample 153: Predicted Label = positive\n",
      "Sample 154: Predicted Label = positive\n",
      "Sample 155: Predicted Label = positive\n",
      "Sample 156: Predicted Label = positive\n",
      "Sample 157: Predicted Label = positive\n",
      "Sample 158: Predicted Label = positive\n",
      "Sample 159: Predicted Label = positive\n",
      "Sample 160: Predicted Label = positive\n",
      "Sample 161: Predicted Label = positive\n",
      "Sample 162: Predicted Label = positive\n",
      "Sample 163: Predicted Label = positive\n",
      "Sample 164: Predicted Label = positive\n",
      "Sample 165: Predicted Label = positive\n",
      "Sample 166: Predicted Label = positive\n",
      "Sample 167: Predicted Label = positive\n",
      "Sample 168: Predicted Label = neutral\n",
      "Sample 169: Predicted Label = positive\n",
      "Sample 170: Predicted Label = positive\n",
      "Sample 171: Predicted Label = positive\n",
      "Sample 172: Predicted Label = positive\n",
      "Sample 173: Predicted Label = positive\n",
      "Sample 174: Predicted Label = positive\n",
      "Sample 175: Predicted Label = positive\n",
      "Sample 176: Predicted Label = positive\n",
      "Sample 177: Predicted Label = positive\n",
      "Sample 178: Predicted Label = positive\n",
      "Sample 179: Predicted Label = positive\n",
      "Sample 180: Predicted Label = positive\n",
      "Sample 181: Predicted Label = positive\n",
      "Sample 182: Predicted Label = positive\n",
      "Sample 183: Predicted Label = positive\n",
      "Sample 184: Predicted Label = positive\n",
      "Sample 185: Predicted Label = positive\n",
      "Sample 186: Predicted Label = positive\n",
      "Sample 187: Predicted Label = positive\n",
      "Sample 188: Predicted Label = positive\n",
      "Sample 189: Predicted Label = positive\n",
      "Sample 190: Predicted Label = positive\n",
      "Sample 191: Predicted Label = positive\n",
      "Sample 192: Predicted Label = positive\n",
      "Sample 193: Predicted Label = positive\n",
      "Sample 194: Predicted Label = positive\n",
      "Sample 195: Predicted Label = positive\n",
      "Sample 196: Predicted Label = positive\n",
      "Sample 197: Predicted Label = positive\n",
      "Sample 198: Predicted Label = positive\n",
      "Sample 199: Predicted Label = positive\n",
      "Sample 200: Predicted Label = positive\n",
      "Sample 201: Predicted Label = positive\n",
      "Sample 202: Predicted Label = positive\n",
      "Sample 203: Predicted Label = positive\n",
      "Sample 204: Predicted Label = positive\n",
      "Sample 205: Predicted Label = positive\n",
      "Sample 206: Predicted Label = positive\n",
      "Sample 207: Predicted Label = positive\n",
      "Sample 208: Predicted Label = positive\n",
      "Sample 209: Predicted Label = positive\n",
      "Sample 210: Predicted Label = positive\n",
      "Sample 211: Predicted Label = positive\n",
      "Sample 212: Predicted Label = positive\n",
      "Sample 213: Predicted Label = positive\n",
      "Sample 214: Predicted Label = positive\n",
      "Sample 215: Predicted Label = positive\n",
      "Sample 216: Predicted Label = positive\n",
      "Sample 217: Predicted Label = positive\n",
      "Sample 218: Predicted Label = positive\n",
      "Sample 219: Predicted Label = positive\n",
      "Sample 220: Predicted Label = positive\n",
      "Sample 221: Predicted Label = positive\n",
      "Sample 222: Predicted Label = positive\n",
      "Sample 223: Predicted Label = positive\n",
      "Sample 224: Predicted Label = positive\n",
      "Sample 225: Predicted Label = positive\n",
      "Sample 226: Predicted Label = positive\n",
      "Sample 227: Predicted Label = positive\n",
      "Sample 228: Predicted Label = positive\n",
      "Sample 229: Predicted Label = positive\n",
      "Sample 230: Predicted Label = positive\n",
      "Sample 231: Predicted Label = positive\n",
      "Sample 232: Predicted Label = positive\n",
      "Sample 233: Predicted Label = positive\n",
      "Sample 234: Predicted Label = positive\n",
      "Sample 235: Predicted Label = positive\n",
      "Sample 236: Predicted Label = positive\n",
      "Sample 237: Predicted Label = positive\n",
      "Sample 238: Predicted Label = positive\n",
      "Sample 239: Predicted Label = positive\n",
      "Sample 240: Predicted Label = positive\n",
      "Sample 241: Predicted Label = positive\n",
      "Sample 242: Predicted Label = positive\n",
      "Sample 243: Predicted Label = positive\n",
      "Sample 244: Predicted Label = positive\n",
      "Sample 245: Predicted Label = positive\n",
      "Sample 246: Predicted Label = positive\n",
      "Sample 247: Predicted Label = positive\n",
      "Sample 248: Predicted Label = positive\n",
      "Sample 249: Predicted Label = positive\n",
      "Sample 250: Predicted Label = positive\n",
      "Sample 251: Predicted Label = positive\n",
      "Sample 252: Predicted Label = positive\n",
      "Sample 253: Predicted Label = positive\n",
      "Sample 254: Predicted Label = positive\n",
      "Sample 255: Predicted Label = positive\n",
      "Sample 256: Predicted Label = positive\n",
      "Sample 257: Predicted Label = positive\n",
      "Sample 258: Predicted Label = positive\n",
      "Sample 259: Predicted Label = positive\n",
      "Sample 260: Predicted Label = positive\n",
      "Sample 261: Predicted Label = positive\n",
      "Sample 262: Predicted Label = positive\n",
      "Sample 263: Predicted Label = positive\n",
      "Sample 264: Predicted Label = positive\n",
      "Sample 265: Predicted Label = positive\n",
      "Sample 266: Predicted Label = positive\n",
      "Sample 267: Predicted Label = positive\n",
      "Sample 268: Predicted Label = positive\n",
      "Sample 269: Predicted Label = positive\n",
      "Sample 270: Predicted Label = positive\n",
      "Sample 271: Predicted Label = positive\n",
      "Sample 272: Predicted Label = positive\n",
      "Sample 273: Predicted Label = positive\n",
      "Sample 274: Predicted Label = positive\n",
      "Sample 275: Predicted Label = positive\n",
      "Sample 276: Predicted Label = positive\n",
      "Sample 277: Predicted Label = positive\n",
      "Sample 278: Predicted Label = positive\n",
      "Sample 279: Predicted Label = positive\n",
      "Sample 280: Predicted Label = positive\n",
      "Sample 281: Predicted Label = positive\n",
      "Sample 282: Predicted Label = positive\n",
      "Sample 283: Predicted Label = positive\n",
      "Sample 284: Predicted Label = positive\n",
      "Sample 285: Predicted Label = positive\n",
      "Sample 286: Predicted Label = positive\n",
      "Sample 287: Predicted Label = positive\n",
      "Sample 288: Predicted Label = positive\n",
      "Sample 289: Predicted Label = positive\n",
      "Sample 290: Predicted Label = positive\n",
      "Sample 291: Predicted Label = positive\n",
      "Sample 292: Predicted Label = positive\n",
      "Sample 293: Predicted Label = positive\n",
      "Sample 294: Predicted Label = positive\n",
      "Sample 295: Predicted Label = positive\n",
      "Sample 296: Predicted Label = positive\n",
      "Sample 297: Predicted Label = positive\n",
      "Sample 298: Predicted Label = positive\n",
      "Sample 299: Predicted Label = positive\n",
      "Sample 300: Predicted Label = positive\n",
      "Sample 301: Predicted Label = positive\n",
      "Sample 302: Predicted Label = positive\n",
      "Sample 303: Predicted Label = positive\n",
      "Sample 304: Predicted Label = positive\n",
      "Sample 305: Predicted Label = positive\n",
      "Sample 306: Predicted Label = positive\n",
      "Sample 307: Predicted Label = positive\n",
      "Sample 308: Predicted Label = positive\n",
      "Sample 309: Predicted Label = positive\n",
      "Sample 310: Predicted Label = positive\n",
      "Sample 311: Predicted Label = positive\n",
      "Sample 312: Predicted Label = positive\n",
      "Sample 313: Predicted Label = positive\n",
      "Sample 314: Predicted Label = positive\n",
      "Sample 315: Predicted Label = positive\n",
      "Sample 316: Predicted Label = positive\n",
      "Sample 317: Predicted Label = positive\n",
      "Sample 318: Predicted Label = positive\n",
      "Sample 319: Predicted Label = positive\n",
      "Sample 320: Predicted Label = positive\n",
      "Sample 321: Predicted Label = positive\n",
      "Sample 322: Predicted Label = positive\n",
      "Sample 323: Predicted Label = positive\n",
      "Sample 324: Predicted Label = positive\n",
      "Sample 325: Predicted Label = positive\n",
      "Sample 326: Predicted Label = positive\n",
      "Sample 327: Predicted Label = positive\n",
      "Sample 328: Predicted Label = positive\n",
      "Sample 329: Predicted Label = positive\n",
      "Sample 330: Predicted Label = positive\n",
      "Sample 331: Predicted Label = positive\n",
      "Sample 332: Predicted Label = positive\n",
      "Sample 333: Predicted Label = positive\n",
      "Sample 334: Predicted Label = positive\n",
      "Sample 335: Predicted Label = positive\n",
      "Sample 336: Predicted Label = positive\n",
      "Sample 337: Predicted Label = positive\n",
      "Sample 338: Predicted Label = positive\n",
      "Sample 339: Predicted Label = positive\n",
      "Sample 340: Predicted Label = positive\n",
      "Sample 341: Predicted Label = positive\n",
      "Sample 342: Predicted Label = positive\n",
      "Sample 343: Predicted Label = positive\n",
      "Sample 344: Predicted Label = positive\n",
      "Sample 345: Predicted Label = positive\n",
      "Sample 346: Predicted Label = positive\n",
      "Sample 347: Predicted Label = positive\n",
      "Sample 348: Predicted Label = positive\n",
      "Sample 349: Predicted Label = positive\n",
      "Sample 350: Predicted Label = positive\n",
      "Sample 351: Predicted Label = positive\n",
      "Sample 352: Predicted Label = positive\n",
      "Sample 353: Predicted Label = positive\n",
      "Sample 354: Predicted Label = positive\n",
      "Sample 355: Predicted Label = positive\n",
      "Sample 356: Predicted Label = positive\n",
      "Sample 357: Predicted Label = positive\n",
      "Sample 358: Predicted Label = positive\n",
      "Sample 359: Predicted Label = positive\n",
      "Sample 360: Predicted Label = positive\n",
      "Sample 361: Predicted Label = positive\n",
      "Sample 362: Predicted Label = positive\n",
      "Sample 363: Predicted Label = positive\n",
      "Sample 364: Predicted Label = positive\n",
      "Sample 365: Predicted Label = positive\n",
      "Sample 366: Predicted Label = positive\n",
      "Sample 367: Predicted Label = positive\n",
      "Sample 368: Predicted Label = positive\n",
      "Sample 369: Predicted Label = positive\n",
      "Sample 370: Predicted Label = positive\n",
      "Sample 371: Predicted Label = positive\n",
      "Sample 372: Predicted Label = positive\n",
      "Sample 373: Predicted Label = positive\n",
      "Sample 374: Predicted Label = positive\n",
      "Sample 375: Predicted Label = positive\n",
      "Sample 376: Predicted Label = positive\n",
      "Sample 377: Predicted Label = positive\n",
      "Sample 378: Predicted Label = positive\n",
      "Sample 379: Predicted Label = positive\n",
      "Sample 380: Predicted Label = positive\n",
      "Sample 381: Predicted Label = positive\n",
      "Sample 382: Predicted Label = positive\n",
      "Sample 383: Predicted Label = positive\n",
      "Sample 384: Predicted Label = positive\n",
      "Sample 385: Predicted Label = positive\n",
      "Sample 386: Predicted Label = positive\n",
      "Sample 387: Predicted Label = positive\n",
      "Sample 388: Predicted Label = positive\n",
      "Sample 389: Predicted Label = positive\n",
      "Sample 390: Predicted Label = positive\n",
      "Sample 391: Predicted Label = neutral\n",
      "Sample 392: Predicted Label = positive\n",
      "Sample 393: Predicted Label = positive\n",
      "Sample 394: Predicted Label = positive\n",
      "Sample 395: Predicted Label = positive\n",
      "Sample 396: Predicted Label = positive\n",
      "Sample 397: Predicted Label = positive\n",
      "Sample 398: Predicted Label = positive\n",
      "Sample 399: Predicted Label = positive\n",
      "Sample 400: Predicted Label = positive\n",
      "Sample 401: Predicted Label = positive\n",
      "Sample 402: Predicted Label = positive\n",
      "Sample 403: Predicted Label = positive\n",
      "Sample 404: Predicted Label = positive\n",
      "Sample 405: Predicted Label = positive\n",
      "Sample 406: Predicted Label = positive\n",
      "Sample 407: Predicted Label = positive\n",
      "Sample 408: Predicted Label = positive\n",
      "Sample 409: Predicted Label = positive\n",
      "Sample 410: Predicted Label = positive\n",
      "Sample 411: Predicted Label = positive\n",
      "Sample 412: Predicted Label = positive\n",
      "Sample 413: Predicted Label = positive\n",
      "Sample 414: Predicted Label = positive\n",
      "Sample 415: Predicted Label = positive\n",
      "Sample 416: Predicted Label = positive\n",
      "Sample 417: Predicted Label = positive\n",
      "Sample 418: Predicted Label = positive\n",
      "Sample 419: Predicted Label = positive\n",
      "Sample 420: Predicted Label = positive\n",
      "Sample 421: Predicted Label = positive\n",
      "Sample 422: Predicted Label = positive\n",
      "Sample 423: Predicted Label = positive\n",
      "Sample 424: Predicted Label = positive\n",
      "Sample 425: Predicted Label = positive\n",
      "Sample 426: Predicted Label = positive\n",
      "Sample 427: Predicted Label = positive\n",
      "Sample 428: Predicted Label = positive\n",
      "Sample 429: Predicted Label = positive\n",
      "Sample 430: Predicted Label = positive\n",
      "Sample 431: Predicted Label = positive\n",
      "Sample 432: Predicted Label = positive\n",
      "Sample 433: Predicted Label = positive\n",
      "Sample 434: Predicted Label = positive\n",
      "Sample 435: Predicted Label = positive\n",
      "Sample 436: Predicted Label = positive\n",
      "Sample 437: Predicted Label = positive\n",
      "Sample 438: Predicted Label = positive\n",
      "Sample 439: Predicted Label = positive\n",
      "Sample 440: Predicted Label = positive\n",
      "Sample 441: Predicted Label = positive\n",
      "Sample 442: Predicted Label = positive\n",
      "Sample 443: Predicted Label = positive\n",
      "Sample 444: Predicted Label = positive\n",
      "Sample 445: Predicted Label = positive\n",
      "Sample 446: Predicted Label = positive\n",
      "Sample 447: Predicted Label = positive\n",
      "Sample 448: Predicted Label = positive\n",
      "Sample 449: Predicted Label = positive\n",
      "Sample 450: Predicted Label = positive\n",
      "Sample 451: Predicted Label = positive\n",
      "Sample 452: Predicted Label = positive\n",
      "Sample 453: Predicted Label = positive\n",
      "Sample 454: Predicted Label = positive\n",
      "Sample 455: Predicted Label = positive\n",
      "Sample 456: Predicted Label = positive\n",
      "Sample 457: Predicted Label = positive\n",
      "Sample 458: Predicted Label = positive\n",
      "Sample 459: Predicted Label = positive\n",
      "Sample 460: Predicted Label = positive\n",
      "Sample 461: Predicted Label = positive\n",
      "Sample 462: Predicted Label = positive\n",
      "Sample 463: Predicted Label = positive\n",
      "Sample 464: Predicted Label = positive\n",
      "Sample 465: Predicted Label = positive\n",
      "Sample 466: Predicted Label = positive\n",
      "Sample 467: Predicted Label = positive\n",
      "Sample 468: Predicted Label = positive\n",
      "Sample 469: Predicted Label = positive\n",
      "Sample 470: Predicted Label = positive\n",
      "Sample 471: Predicted Label = positive\n",
      "Sample 472: Predicted Label = positive\n",
      "Sample 473: Predicted Label = positive\n",
      "Sample 474: Predicted Label = positive\n",
      "Sample 475: Predicted Label = positive\n",
      "Sample 476: Predicted Label = positive\n",
      "Sample 477: Predicted Label = positive\n",
      "Sample 478: Predicted Label = positive\n",
      "Sample 479: Predicted Label = positive\n",
      "Sample 480: Predicted Label = positive\n",
      "Sample 481: Predicted Label = positive\n",
      "Sample 482: Predicted Label = positive\n",
      "Sample 483: Predicted Label = positive\n",
      "Sample 484: Predicted Label = positive\n",
      "Sample 485: Predicted Label = positive\n",
      "Sample 486: Predicted Label = positive\n",
      "Sample 487: Predicted Label = positive\n",
      "Sample 488: Predicted Label = positive\n",
      "Sample 489: Predicted Label = positive\n",
      "Sample 490: Predicted Label = positive\n",
      "Sample 491: Predicted Label = positive\n",
      "Sample 492: Predicted Label = positive\n",
      "Sample 493: Predicted Label = positive\n",
      "Sample 494: Predicted Label = positive\n",
      "Sample 495: Predicted Label = positive\n",
      "Sample 496: Predicted Label = positive\n",
      "Sample 497: Predicted Label = positive\n",
      "Sample 498: Predicted Label = positive\n",
      "Sample 499: Predicted Label = positive\n",
      "Sample 500: Predicted Label = positive\n",
      "Sample 501: Predicted Label = positive\n",
      "Sample 502: Predicted Label = positive\n",
      "Sample 503: Predicted Label = positive\n",
      "Sample 504: Predicted Label = positive\n",
      "Sample 505: Predicted Label = positive\n",
      "Sample 506: Predicted Label = positive\n",
      "Sample 507: Predicted Label = positive\n",
      "Sample 508: Predicted Label = positive\n",
      "Sample 509: Predicted Label = positive\n",
      "Sample 510: Predicted Label = positive\n",
      "Sample 511: Predicted Label = positive\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "lstm_vgg_predictions = model.predict([test_text_pad, test_image])\n",
    "\n",
    "# 将预测结果转换为标签\n",
    "predicted_labels_1 = np.argmax(lstm_vgg_predictions, axis=1)\n",
    "predicted_labels_1 = [index_to_label[label] for label in predicted_labels_1]\n",
    "\n",
    "# 打印预测结果\n",
    "for i, label in enumerate(predicted_labels_1):\n",
    "    print(f\"Sample {i+1}: Predicted Label = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_1='test_lstm_vgg.txt'\n",
    "with open(file_path_1,'w') as file:\n",
    "    file.write('guid,tag'+'\\n')\n",
    "    for i in range(len(predicted_labels_1)):\n",
    "        file.write(str(test_guid[i])+','+str(predicted_labels_1[i])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将用于图片训练的rggNet改为resnet50试试，把lstm改成双向lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from keras.layers import Input, Flatten, Dense, Concatenate, Bidirectional\n",
    "from keras.models import Model\n",
    "\n",
    "#构建模型\n",
    "image_input_resnet = Input(shape=(224, 224,3))\n",
    "resnet_model  = ResNet50(include_top=False, weights='imagenet', input_tensor=image_input_resnet)\n",
    "image_features_resnet = resnet_model.output\n",
    "image_features_resnet = Flatten()(image_features_resnet)\n",
    "# image_features_resnet = Dropout(rate=0.1)(image_features_resnet)\n",
    "\n",
    "text_input_bilstm=Input(shape=(max_length,))\n",
    "text_embed_bilstm=Embedding(input_dim=len(w2v_word_vocab),output_dim=embedding_dim,weights=[word_vec_matrix.vectors],trainable=False)(text_input_bilstm)\n",
    "lstm_layer=LSTM(units=128)\n",
    "bidirectional_lstm = Bidirectional(lstm_layer)\n",
    "text_features_bilstm = bidirectional_lstm(text_embed_bilstm)\n",
    "# text_features_bilstm = Dropout(rate=0.1)(text_features_bilstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "#构建多模态模型(lstm+resnet)\n",
    "#融合文本和图像特征\n",
    "combined_features_2 = Concatenate()([text_features_bilstm, image_features_resnet])\n",
    "combined_features = Dropout(rate=0.1)(combined_features_2)\n",
    "predictions_2 = Dense(3, activation='softmax')(combined_features_2)\n",
    "#构建多模态融合模型\n",
    "lstm_resnet_model = Model(inputs=[text_input_bilstm, image_input_resnet], outputs=predictions_2)\n",
    "#编译模型\n",
    "learning_rate = 0.0025  # 设置所需的学习率\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "lstm_resnet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# lstm_resnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 20s 120ms/step - loss: 8.7224 - accuracy: 0.5419 - val_loss: 44042.1133 - val_accuracy: 0.5063\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 3.9228 - accuracy: 0.5631 - val_loss: 32.8798 - val_accuracy: 0.5113\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 2.8233 - accuracy: 0.5716 - val_loss: 0.8868 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 2.6109 - accuracy: 0.5722 - val_loss: 0.8949 - val_accuracy: 0.6050\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 10s 98ms/step - loss: 2.8483 - accuracy: 0.5706 - val_loss: 0.8860 - val_accuracy: 0.6050\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 10s 99ms/step - loss: 2.4359 - accuracy: 0.5800 - val_loss: 0.8849 - val_accuracy: 0.6050\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 1.5450 - accuracy: 0.5794 - val_loss: 0.8795 - val_accuracy: 0.6050\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 10s 101ms/step - loss: 1.5081 - accuracy: 0.5828 - val_loss: 0.9749 - val_accuracy: 0.6025\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 1.1148 - accuracy: 0.5816 - val_loss: 0.9043 - val_accuracy: 0.6062\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 10s 103ms/step - loss: 1.0407 - accuracy: 0.5975 - val_loss: 0.9001 - val_accuracy: 0.6025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f693845cb80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_resnet_model.fit(x=[train_text_pad,train_image],y=train_label_one_hot,epochs=10,batch_size=32,validation_data=([val_text_pad,val_image],val_label_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 2s 42ms/step\n",
      "Sample 1: Predicted Label = positive\n",
      "Sample 2: Predicted Label = positive\n",
      "Sample 3: Predicted Label = positive\n",
      "Sample 4: Predicted Label = positive\n",
      "Sample 5: Predicted Label = positive\n",
      "Sample 6: Predicted Label = positive\n",
      "Sample 7: Predicted Label = positive\n",
      "Sample 8: Predicted Label = positive\n",
      "Sample 9: Predicted Label = positive\n",
      "Sample 10: Predicted Label = positive\n",
      "Sample 11: Predicted Label = positive\n",
      "Sample 12: Predicted Label = positive\n",
      "Sample 13: Predicted Label = positive\n",
      "Sample 14: Predicted Label = positive\n",
      "Sample 15: Predicted Label = positive\n",
      "Sample 16: Predicted Label = positive\n",
      "Sample 17: Predicted Label = negative\n",
      "Sample 18: Predicted Label = positive\n",
      "Sample 19: Predicted Label = positive\n",
      "Sample 20: Predicted Label = positive\n",
      "Sample 21: Predicted Label = positive\n",
      "Sample 22: Predicted Label = positive\n",
      "Sample 23: Predicted Label = positive\n",
      "Sample 24: Predicted Label = positive\n",
      "Sample 25: Predicted Label = positive\n",
      "Sample 26: Predicted Label = positive\n",
      "Sample 27: Predicted Label = positive\n",
      "Sample 28: Predicted Label = positive\n",
      "Sample 29: Predicted Label = positive\n",
      "Sample 30: Predicted Label = positive\n",
      "Sample 31: Predicted Label = positive\n",
      "Sample 32: Predicted Label = positive\n",
      "Sample 33: Predicted Label = positive\n",
      "Sample 34: Predicted Label = positive\n",
      "Sample 35: Predicted Label = positive\n",
      "Sample 36: Predicted Label = positive\n",
      "Sample 37: Predicted Label = positive\n",
      "Sample 38: Predicted Label = positive\n",
      "Sample 39: Predicted Label = positive\n",
      "Sample 40: Predicted Label = positive\n",
      "Sample 41: Predicted Label = positive\n",
      "Sample 42: Predicted Label = positive\n",
      "Sample 43: Predicted Label = positive\n",
      "Sample 44: Predicted Label = positive\n",
      "Sample 45: Predicted Label = positive\n",
      "Sample 46: Predicted Label = positive\n",
      "Sample 47: Predicted Label = positive\n",
      "Sample 48: Predicted Label = positive\n",
      "Sample 49: Predicted Label = positive\n",
      "Sample 50: Predicted Label = positive\n",
      "Sample 51: Predicted Label = positive\n",
      "Sample 52: Predicted Label = positive\n",
      "Sample 53: Predicted Label = positive\n",
      "Sample 54: Predicted Label = positive\n",
      "Sample 55: Predicted Label = positive\n",
      "Sample 56: Predicted Label = positive\n",
      "Sample 57: Predicted Label = positive\n",
      "Sample 58: Predicted Label = positive\n",
      "Sample 59: Predicted Label = positive\n",
      "Sample 60: Predicted Label = positive\n",
      "Sample 61: Predicted Label = positive\n",
      "Sample 62: Predicted Label = positive\n",
      "Sample 63: Predicted Label = positive\n",
      "Sample 64: Predicted Label = positive\n",
      "Sample 65: Predicted Label = positive\n",
      "Sample 66: Predicted Label = positive\n",
      "Sample 67: Predicted Label = positive\n",
      "Sample 68: Predicted Label = positive\n",
      "Sample 69: Predicted Label = positive\n",
      "Sample 70: Predicted Label = positive\n",
      "Sample 71: Predicted Label = positive\n",
      "Sample 72: Predicted Label = positive\n",
      "Sample 73: Predicted Label = positive\n",
      "Sample 74: Predicted Label = positive\n",
      "Sample 75: Predicted Label = positive\n",
      "Sample 76: Predicted Label = positive\n",
      "Sample 77: Predicted Label = positive\n",
      "Sample 78: Predicted Label = positive\n",
      "Sample 79: Predicted Label = positive\n",
      "Sample 80: Predicted Label = positive\n",
      "Sample 81: Predicted Label = positive\n",
      "Sample 82: Predicted Label = positive\n",
      "Sample 83: Predicted Label = positive\n",
      "Sample 84: Predicted Label = positive\n",
      "Sample 85: Predicted Label = positive\n",
      "Sample 86: Predicted Label = positive\n",
      "Sample 87: Predicted Label = positive\n",
      "Sample 88: Predicted Label = positive\n",
      "Sample 89: Predicted Label = positive\n",
      "Sample 90: Predicted Label = positive\n",
      "Sample 91: Predicted Label = positive\n",
      "Sample 92: Predicted Label = positive\n",
      "Sample 93: Predicted Label = positive\n",
      "Sample 94: Predicted Label = positive\n",
      "Sample 95: Predicted Label = positive\n",
      "Sample 96: Predicted Label = positive\n",
      "Sample 97: Predicted Label = positive\n",
      "Sample 98: Predicted Label = positive\n",
      "Sample 99: Predicted Label = positive\n",
      "Sample 100: Predicted Label = positive\n",
      "Sample 101: Predicted Label = positive\n",
      "Sample 102: Predicted Label = positive\n",
      "Sample 103: Predicted Label = positive\n",
      "Sample 104: Predicted Label = positive\n",
      "Sample 105: Predicted Label = positive\n",
      "Sample 106: Predicted Label = positive\n",
      "Sample 107: Predicted Label = positive\n",
      "Sample 108: Predicted Label = positive\n",
      "Sample 109: Predicted Label = positive\n",
      "Sample 110: Predicted Label = positive\n",
      "Sample 111: Predicted Label = positive\n",
      "Sample 112: Predicted Label = positive\n",
      "Sample 113: Predicted Label = positive\n",
      "Sample 114: Predicted Label = positive\n",
      "Sample 115: Predicted Label = positive\n",
      "Sample 116: Predicted Label = positive\n",
      "Sample 117: Predicted Label = positive\n",
      "Sample 118: Predicted Label = positive\n",
      "Sample 119: Predicted Label = positive\n",
      "Sample 120: Predicted Label = positive\n",
      "Sample 121: Predicted Label = positive\n",
      "Sample 122: Predicted Label = positive\n",
      "Sample 123: Predicted Label = positive\n",
      "Sample 124: Predicted Label = positive\n",
      "Sample 125: Predicted Label = positive\n",
      "Sample 126: Predicted Label = positive\n",
      "Sample 127: Predicted Label = positive\n",
      "Sample 128: Predicted Label = positive\n",
      "Sample 129: Predicted Label = positive\n",
      "Sample 130: Predicted Label = positive\n",
      "Sample 131: Predicted Label = positive\n",
      "Sample 132: Predicted Label = positive\n",
      "Sample 133: Predicted Label = positive\n",
      "Sample 134: Predicted Label = positive\n",
      "Sample 135: Predicted Label = negative\n",
      "Sample 136: Predicted Label = positive\n",
      "Sample 137: Predicted Label = positive\n",
      "Sample 138: Predicted Label = positive\n",
      "Sample 139: Predicted Label = positive\n",
      "Sample 140: Predicted Label = positive\n",
      "Sample 141: Predicted Label = positive\n",
      "Sample 142: Predicted Label = positive\n",
      "Sample 143: Predicted Label = positive\n",
      "Sample 144: Predicted Label = positive\n",
      "Sample 145: Predicted Label = positive\n",
      "Sample 146: Predicted Label = positive\n",
      "Sample 147: Predicted Label = positive\n",
      "Sample 148: Predicted Label = positive\n",
      "Sample 149: Predicted Label = positive\n",
      "Sample 150: Predicted Label = positive\n",
      "Sample 151: Predicted Label = positive\n",
      "Sample 152: Predicted Label = positive\n",
      "Sample 153: Predicted Label = positive\n",
      "Sample 154: Predicted Label = positive\n",
      "Sample 155: Predicted Label = positive\n",
      "Sample 156: Predicted Label = positive\n",
      "Sample 157: Predicted Label = positive\n",
      "Sample 158: Predicted Label = positive\n",
      "Sample 159: Predicted Label = positive\n",
      "Sample 160: Predicted Label = positive\n",
      "Sample 161: Predicted Label = positive\n",
      "Sample 162: Predicted Label = positive\n",
      "Sample 163: Predicted Label = positive\n",
      "Sample 164: Predicted Label = positive\n",
      "Sample 165: Predicted Label = positive\n",
      "Sample 166: Predicted Label = positive\n",
      "Sample 167: Predicted Label = positive\n",
      "Sample 168: Predicted Label = positive\n",
      "Sample 169: Predicted Label = positive\n",
      "Sample 170: Predicted Label = positive\n",
      "Sample 171: Predicted Label = positive\n",
      "Sample 172: Predicted Label = positive\n",
      "Sample 173: Predicted Label = positive\n",
      "Sample 174: Predicted Label = positive\n",
      "Sample 175: Predicted Label = positive\n",
      "Sample 176: Predicted Label = positive\n",
      "Sample 177: Predicted Label = positive\n",
      "Sample 178: Predicted Label = positive\n",
      "Sample 179: Predicted Label = positive\n",
      "Sample 180: Predicted Label = positive\n",
      "Sample 181: Predicted Label = positive\n",
      "Sample 182: Predicted Label = positive\n",
      "Sample 183: Predicted Label = positive\n",
      "Sample 184: Predicted Label = positive\n",
      "Sample 185: Predicted Label = positive\n",
      "Sample 186: Predicted Label = positive\n",
      "Sample 187: Predicted Label = positive\n",
      "Sample 188: Predicted Label = positive\n",
      "Sample 189: Predicted Label = positive\n",
      "Sample 190: Predicted Label = positive\n",
      "Sample 191: Predicted Label = positive\n",
      "Sample 192: Predicted Label = positive\n",
      "Sample 193: Predicted Label = positive\n",
      "Sample 194: Predicted Label = positive\n",
      "Sample 195: Predicted Label = positive\n",
      "Sample 196: Predicted Label = positive\n",
      "Sample 197: Predicted Label = positive\n",
      "Sample 198: Predicted Label = positive\n",
      "Sample 199: Predicted Label = positive\n",
      "Sample 200: Predicted Label = positive\n",
      "Sample 201: Predicted Label = positive\n",
      "Sample 202: Predicted Label = positive\n",
      "Sample 203: Predicted Label = positive\n",
      "Sample 204: Predicted Label = positive\n",
      "Sample 205: Predicted Label = positive\n",
      "Sample 206: Predicted Label = positive\n",
      "Sample 207: Predicted Label = positive\n",
      "Sample 208: Predicted Label = positive\n",
      "Sample 209: Predicted Label = positive\n",
      "Sample 210: Predicted Label = positive\n",
      "Sample 211: Predicted Label = positive\n",
      "Sample 212: Predicted Label = positive\n",
      "Sample 213: Predicted Label = positive\n",
      "Sample 214: Predicted Label = positive\n",
      "Sample 215: Predicted Label = positive\n",
      "Sample 216: Predicted Label = positive\n",
      "Sample 217: Predicted Label = positive\n",
      "Sample 218: Predicted Label = positive\n",
      "Sample 219: Predicted Label = positive\n",
      "Sample 220: Predicted Label = positive\n",
      "Sample 221: Predicted Label = positive\n",
      "Sample 222: Predicted Label = positive\n",
      "Sample 223: Predicted Label = positive\n",
      "Sample 224: Predicted Label = positive\n",
      "Sample 225: Predicted Label = positive\n",
      "Sample 226: Predicted Label = positive\n",
      "Sample 227: Predicted Label = positive\n",
      "Sample 228: Predicted Label = positive\n",
      "Sample 229: Predicted Label = positive\n",
      "Sample 230: Predicted Label = positive\n",
      "Sample 231: Predicted Label = positive\n",
      "Sample 232: Predicted Label = positive\n",
      "Sample 233: Predicted Label = positive\n",
      "Sample 234: Predicted Label = positive\n",
      "Sample 235: Predicted Label = positive\n",
      "Sample 236: Predicted Label = positive\n",
      "Sample 237: Predicted Label = positive\n",
      "Sample 238: Predicted Label = positive\n",
      "Sample 239: Predicted Label = positive\n",
      "Sample 240: Predicted Label = positive\n",
      "Sample 241: Predicted Label = positive\n",
      "Sample 242: Predicted Label = positive\n",
      "Sample 243: Predicted Label = positive\n",
      "Sample 244: Predicted Label = positive\n",
      "Sample 245: Predicted Label = positive\n",
      "Sample 246: Predicted Label = positive\n",
      "Sample 247: Predicted Label = positive\n",
      "Sample 248: Predicted Label = positive\n",
      "Sample 249: Predicted Label = positive\n",
      "Sample 250: Predicted Label = negative\n",
      "Sample 251: Predicted Label = positive\n",
      "Sample 252: Predicted Label = positive\n",
      "Sample 253: Predicted Label = positive\n",
      "Sample 254: Predicted Label = positive\n",
      "Sample 255: Predicted Label = positive\n",
      "Sample 256: Predicted Label = positive\n",
      "Sample 257: Predicted Label = positive\n",
      "Sample 258: Predicted Label = positive\n",
      "Sample 259: Predicted Label = positive\n",
      "Sample 260: Predicted Label = positive\n",
      "Sample 261: Predicted Label = positive\n",
      "Sample 262: Predicted Label = positive\n",
      "Sample 263: Predicted Label = positive\n",
      "Sample 264: Predicted Label = positive\n",
      "Sample 265: Predicted Label = positive\n",
      "Sample 266: Predicted Label = positive\n",
      "Sample 267: Predicted Label = positive\n",
      "Sample 268: Predicted Label = positive\n",
      "Sample 269: Predicted Label = positive\n",
      "Sample 270: Predicted Label = positive\n",
      "Sample 271: Predicted Label = positive\n",
      "Sample 272: Predicted Label = positive\n",
      "Sample 273: Predicted Label = positive\n",
      "Sample 274: Predicted Label = positive\n",
      "Sample 275: Predicted Label = positive\n",
      "Sample 276: Predicted Label = positive\n",
      "Sample 277: Predicted Label = positive\n",
      "Sample 278: Predicted Label = positive\n",
      "Sample 279: Predicted Label = positive\n",
      "Sample 280: Predicted Label = positive\n",
      "Sample 281: Predicted Label = positive\n",
      "Sample 282: Predicted Label = positive\n",
      "Sample 283: Predicted Label = positive\n",
      "Sample 284: Predicted Label = positive\n",
      "Sample 285: Predicted Label = positive\n",
      "Sample 286: Predicted Label = positive\n",
      "Sample 287: Predicted Label = positive\n",
      "Sample 288: Predicted Label = positive\n",
      "Sample 289: Predicted Label = positive\n",
      "Sample 290: Predicted Label = positive\n",
      "Sample 291: Predicted Label = positive\n",
      "Sample 292: Predicted Label = positive\n",
      "Sample 293: Predicted Label = negative\n",
      "Sample 294: Predicted Label = positive\n",
      "Sample 295: Predicted Label = positive\n",
      "Sample 296: Predicted Label = positive\n",
      "Sample 297: Predicted Label = positive\n",
      "Sample 298: Predicted Label = positive\n",
      "Sample 299: Predicted Label = positive\n",
      "Sample 300: Predicted Label = positive\n",
      "Sample 301: Predicted Label = positive\n",
      "Sample 302: Predicted Label = positive\n",
      "Sample 303: Predicted Label = positive\n",
      "Sample 304: Predicted Label = positive\n",
      "Sample 305: Predicted Label = positive\n",
      "Sample 306: Predicted Label = positive\n",
      "Sample 307: Predicted Label = positive\n",
      "Sample 308: Predicted Label = positive\n",
      "Sample 309: Predicted Label = positive\n",
      "Sample 310: Predicted Label = positive\n",
      "Sample 311: Predicted Label = positive\n",
      "Sample 312: Predicted Label = positive\n",
      "Sample 313: Predicted Label = positive\n",
      "Sample 314: Predicted Label = positive\n",
      "Sample 315: Predicted Label = positive\n",
      "Sample 316: Predicted Label = positive\n",
      "Sample 317: Predicted Label = positive\n",
      "Sample 318: Predicted Label = positive\n",
      "Sample 319: Predicted Label = positive\n",
      "Sample 320: Predicted Label = neutral\n",
      "Sample 321: Predicted Label = positive\n",
      "Sample 322: Predicted Label = positive\n",
      "Sample 323: Predicted Label = positive\n",
      "Sample 324: Predicted Label = positive\n",
      "Sample 325: Predicted Label = positive\n",
      "Sample 326: Predicted Label = positive\n",
      "Sample 327: Predicted Label = positive\n",
      "Sample 328: Predicted Label = positive\n",
      "Sample 329: Predicted Label = positive\n",
      "Sample 330: Predicted Label = positive\n",
      "Sample 331: Predicted Label = positive\n",
      "Sample 332: Predicted Label = positive\n",
      "Sample 333: Predicted Label = positive\n",
      "Sample 334: Predicted Label = positive\n",
      "Sample 335: Predicted Label = positive\n",
      "Sample 336: Predicted Label = positive\n",
      "Sample 337: Predicted Label = positive\n",
      "Sample 338: Predicted Label = positive\n",
      "Sample 339: Predicted Label = positive\n",
      "Sample 340: Predicted Label = positive\n",
      "Sample 341: Predicted Label = positive\n",
      "Sample 342: Predicted Label = positive\n",
      "Sample 343: Predicted Label = positive\n",
      "Sample 344: Predicted Label = positive\n",
      "Sample 345: Predicted Label = positive\n",
      "Sample 346: Predicted Label = positive\n",
      "Sample 347: Predicted Label = positive\n",
      "Sample 348: Predicted Label = positive\n",
      "Sample 349: Predicted Label = positive\n",
      "Sample 350: Predicted Label = positive\n",
      "Sample 351: Predicted Label = positive\n",
      "Sample 352: Predicted Label = positive\n",
      "Sample 353: Predicted Label = positive\n",
      "Sample 354: Predicted Label = positive\n",
      "Sample 355: Predicted Label = positive\n",
      "Sample 356: Predicted Label = positive\n",
      "Sample 357: Predicted Label = positive\n",
      "Sample 358: Predicted Label = positive\n",
      "Sample 359: Predicted Label = positive\n",
      "Sample 360: Predicted Label = positive\n",
      "Sample 361: Predicted Label = positive\n",
      "Sample 362: Predicted Label = positive\n",
      "Sample 363: Predicted Label = positive\n",
      "Sample 364: Predicted Label = positive\n",
      "Sample 365: Predicted Label = positive\n",
      "Sample 366: Predicted Label = positive\n",
      "Sample 367: Predicted Label = positive\n",
      "Sample 368: Predicted Label = positive\n",
      "Sample 369: Predicted Label = positive\n",
      "Sample 370: Predicted Label = positive\n",
      "Sample 371: Predicted Label = positive\n",
      "Sample 372: Predicted Label = positive\n",
      "Sample 373: Predicted Label = positive\n",
      "Sample 374: Predicted Label = positive\n",
      "Sample 375: Predicted Label = positive\n",
      "Sample 376: Predicted Label = positive\n",
      "Sample 377: Predicted Label = positive\n",
      "Sample 378: Predicted Label = positive\n",
      "Sample 379: Predicted Label = positive\n",
      "Sample 380: Predicted Label = positive\n",
      "Sample 381: Predicted Label = positive\n",
      "Sample 382: Predicted Label = positive\n",
      "Sample 383: Predicted Label = positive\n",
      "Sample 384: Predicted Label = positive\n",
      "Sample 385: Predicted Label = positive\n",
      "Sample 386: Predicted Label = positive\n",
      "Sample 387: Predicted Label = positive\n",
      "Sample 388: Predicted Label = positive\n",
      "Sample 389: Predicted Label = positive\n",
      "Sample 390: Predicted Label = positive\n",
      "Sample 391: Predicted Label = positive\n",
      "Sample 392: Predicted Label = positive\n",
      "Sample 393: Predicted Label = positive\n",
      "Sample 394: Predicted Label = positive\n",
      "Sample 395: Predicted Label = positive\n",
      "Sample 396: Predicted Label = positive\n",
      "Sample 397: Predicted Label = positive\n",
      "Sample 398: Predicted Label = positive\n",
      "Sample 399: Predicted Label = positive\n",
      "Sample 400: Predicted Label = positive\n",
      "Sample 401: Predicted Label = positive\n",
      "Sample 402: Predicted Label = positive\n",
      "Sample 403: Predicted Label = positive\n",
      "Sample 404: Predicted Label = positive\n",
      "Sample 405: Predicted Label = positive\n",
      "Sample 406: Predicted Label = positive\n",
      "Sample 407: Predicted Label = positive\n",
      "Sample 408: Predicted Label = positive\n",
      "Sample 409: Predicted Label = positive\n",
      "Sample 410: Predicted Label = positive\n",
      "Sample 411: Predicted Label = positive\n",
      "Sample 412: Predicted Label = positive\n",
      "Sample 413: Predicted Label = positive\n",
      "Sample 414: Predicted Label = positive\n",
      "Sample 415: Predicted Label = positive\n",
      "Sample 416: Predicted Label = positive\n",
      "Sample 417: Predicted Label = positive\n",
      "Sample 418: Predicted Label = negative\n",
      "Sample 419: Predicted Label = positive\n",
      "Sample 420: Predicted Label = positive\n",
      "Sample 421: Predicted Label = positive\n",
      "Sample 422: Predicted Label = positive\n",
      "Sample 423: Predicted Label = positive\n",
      "Sample 424: Predicted Label = positive\n",
      "Sample 425: Predicted Label = positive\n",
      "Sample 426: Predicted Label = positive\n",
      "Sample 427: Predicted Label = positive\n",
      "Sample 428: Predicted Label = positive\n",
      "Sample 429: Predicted Label = positive\n",
      "Sample 430: Predicted Label = positive\n",
      "Sample 431: Predicted Label = positive\n",
      "Sample 432: Predicted Label = positive\n",
      "Sample 433: Predicted Label = positive\n",
      "Sample 434: Predicted Label = positive\n",
      "Sample 435: Predicted Label = positive\n",
      "Sample 436: Predicted Label = positive\n",
      "Sample 437: Predicted Label = positive\n",
      "Sample 438: Predicted Label = positive\n",
      "Sample 439: Predicted Label = positive\n",
      "Sample 440: Predicted Label = positive\n",
      "Sample 441: Predicted Label = positive\n",
      "Sample 442: Predicted Label = positive\n",
      "Sample 443: Predicted Label = positive\n",
      "Sample 444: Predicted Label = positive\n",
      "Sample 445: Predicted Label = positive\n",
      "Sample 446: Predicted Label = positive\n",
      "Sample 447: Predicted Label = positive\n",
      "Sample 448: Predicted Label = positive\n",
      "Sample 449: Predicted Label = positive\n",
      "Sample 450: Predicted Label = positive\n",
      "Sample 451: Predicted Label = positive\n",
      "Sample 452: Predicted Label = positive\n",
      "Sample 453: Predicted Label = positive\n",
      "Sample 454: Predicted Label = positive\n",
      "Sample 455: Predicted Label = positive\n",
      "Sample 456: Predicted Label = positive\n",
      "Sample 457: Predicted Label = positive\n",
      "Sample 458: Predicted Label = positive\n",
      "Sample 459: Predicted Label = positive\n",
      "Sample 460: Predicted Label = positive\n",
      "Sample 461: Predicted Label = positive\n",
      "Sample 462: Predicted Label = positive\n",
      "Sample 463: Predicted Label = positive\n",
      "Sample 464: Predicted Label = positive\n",
      "Sample 465: Predicted Label = positive\n",
      "Sample 466: Predicted Label = positive\n",
      "Sample 467: Predicted Label = positive\n",
      "Sample 468: Predicted Label = positive\n",
      "Sample 469: Predicted Label = positive\n",
      "Sample 470: Predicted Label = negative\n",
      "Sample 471: Predicted Label = positive\n",
      "Sample 472: Predicted Label = positive\n",
      "Sample 473: Predicted Label = positive\n",
      "Sample 474: Predicted Label = positive\n",
      "Sample 475: Predicted Label = positive\n",
      "Sample 476: Predicted Label = positive\n",
      "Sample 477: Predicted Label = positive\n",
      "Sample 478: Predicted Label = positive\n",
      "Sample 479: Predicted Label = positive\n",
      "Sample 480: Predicted Label = positive\n",
      "Sample 481: Predicted Label = positive\n",
      "Sample 482: Predicted Label = positive\n",
      "Sample 483: Predicted Label = positive\n",
      "Sample 484: Predicted Label = positive\n",
      "Sample 485: Predicted Label = positive\n",
      "Sample 486: Predicted Label = positive\n",
      "Sample 487: Predicted Label = positive\n",
      "Sample 488: Predicted Label = positive\n",
      "Sample 489: Predicted Label = positive\n",
      "Sample 490: Predicted Label = positive\n",
      "Sample 491: Predicted Label = positive\n",
      "Sample 492: Predicted Label = positive\n",
      "Sample 493: Predicted Label = positive\n",
      "Sample 494: Predicted Label = positive\n",
      "Sample 495: Predicted Label = positive\n",
      "Sample 496: Predicted Label = positive\n",
      "Sample 497: Predicted Label = positive\n",
      "Sample 498: Predicted Label = positive\n",
      "Sample 499: Predicted Label = positive\n",
      "Sample 500: Predicted Label = positive\n",
      "Sample 501: Predicted Label = positive\n",
      "Sample 502: Predicted Label = positive\n",
      "Sample 503: Predicted Label = positive\n",
      "Sample 504: Predicted Label = positive\n",
      "Sample 505: Predicted Label = positive\n",
      "Sample 506: Predicted Label = positive\n",
      "Sample 507: Predicted Label = positive\n",
      "Sample 508: Predicted Label = positive\n",
      "Sample 509: Predicted Label = positive\n",
      "Sample 510: Predicted Label = positive\n",
      "Sample 511: Predicted Label = positive\n"
     ]
    }
   ],
   "source": [
    "# 使用模型进行预测\n",
    "lstm_resnet_predictions = lstm_resnet_model.predict([test_text_pad, test_image])\n",
    "\n",
    "# 将预测结果转换为标签\n",
    "predicted_labels = np.argmax(lstm_resnet_predictions, axis=1)\n",
    "predicted_labels = [index_to_label[label] for label in predicted_labels]\n",
    "\n",
    "# 打印预测结果\n",
    "for i, label in enumerate(predicted_labels):\n",
    "    print(f\"Sample {i+1}: Predicted Label = {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_2='test_bilstm_resnet.txt'\n",
    "with open(file_path_2,'w') as file:\n",
    "    file.write('guid,tag'+'\\n')\n",
    "    for i in range(len(predicted_labels)):\n",
    "        file.write(str(test_guid[i])+','+str(predicted_labels[i])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 消融实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 消融实验1：lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 2s 10ms/step - loss: 0.9082 - accuracy: 0.5822 - val_loss: 0.8972 - val_accuracy: 0.6050\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 5ms/step - loss: 0.8953 - accuracy: 0.5947 - val_loss: 0.8914 - val_accuracy: 0.6050\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8933 - accuracy: 0.5950 - val_loss: 0.8909 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8908 - accuracy: 0.5944 - val_loss: 0.8861 - val_accuracy: 0.6050\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8890 - accuracy: 0.5944 - val_loss: 0.8880 - val_accuracy: 0.6050\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8884 - accuracy: 0.5941 - val_loss: 0.8918 - val_accuracy: 0.6050\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8882 - accuracy: 0.5950 - val_loss: 0.8877 - val_accuracy: 0.6050\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8868 - accuracy: 0.5950 - val_loss: 0.8887 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.8841 - accuracy: 0.5947 - val_loss: 0.8913 - val_accuracy: 0.6037\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 7ms/step - loss: 0.8838 - accuracy: 0.5947 - val_loss: 0.8920 - val_accuracy: 0.6012\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8920 - accuracy: 0.6012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8920366168022156, 0.6012499928474426]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_text = Dense(3, activation='softmax')(text_features)\n",
    "\n",
    "# 构建仅文本输入的模型\n",
    "text_model = Model(inputs=text_input, outputs=predictions_text)\n",
    "text_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 仅使用文本数据进行训练\n",
    "text_model.fit(train_text_pad, train_label_one_hot, epochs=10, batch_size=32, validation_data=(val_text_pad, val_label_one_hot))\n",
    "\n",
    "# 在验证集上评估模型\n",
    "text_model.evaluate(val_text_pad, val_label_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 消融实验2：vggnet_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 16s 149ms/step - loss: 0.9355 - accuracy: 0.5838 - val_loss: 0.9193 - val_accuracy: 0.6050\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 14s 145ms/step - loss: 0.9225 - accuracy: 0.5950 - val_loss: 0.9088 - val_accuracy: 0.6050\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.9436 - accuracy: 0.5903 - val_loss: 0.9488 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 14s 144ms/step - loss: 0.9133 - accuracy: 0.5950 - val_loss: 0.9014 - val_accuracy: 0.6050\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 15s 146ms/step - loss: 0.9092 - accuracy: 0.5950 - val_loss: 0.9010 - val_accuracy: 0.6050\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 16s 156ms/step - loss: 0.9093 - accuracy: 0.5950 - val_loss: 0.9021 - val_accuracy: 0.6050\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 15s 152ms/step - loss: 0.9124 - accuracy: 0.5950 - val_loss: 0.9021 - val_accuracy: 0.6050\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 15s 147ms/step - loss: 0.9087 - accuracy: 0.5950 - val_loss: 0.9047 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.9111 - accuracy: 0.5950 - val_loss: 0.8997 - val_accuracy: 0.6050\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 15s 154ms/step - loss: 0.9089 - accuracy: 0.5950 - val_loss: 0.8998 - val_accuracy: 0.6050\n",
      "25/25 [==============================] - 1s 45ms/step - loss: 0.8998 - accuracy: 0.6050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8997756242752075, 0.6050000190734863]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_images = Dense(3, activation='softmax')(image_features)\n",
    "# 构建仅图像输入的模型\n",
    "image_model = Model(inputs=image_input, outputs=predictions_images)\n",
    "image_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 仅使用图像数据进行训练\n",
    "image_model.fit(train_image, train_label_one_hot, epochs=10, batch_size=32, validation_data=(val_image, val_label_one_hot))\n",
    "\n",
    "# 在验证集上评估模型\n",
    "image_model.evaluate(val_image, val_label_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 消融实验3：bi-lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 4s 15ms/step - loss: 0.9009 - accuracy: 0.5888 - val_loss: 0.8848 - val_accuracy: 0.6050\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8868 - accuracy: 0.5950 - val_loss: 0.8786 - val_accuracy: 0.6050\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8850 - accuracy: 0.5953 - val_loss: 0.8885 - val_accuracy: 0.6050\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 1s 10ms/step - loss: 0.8895 - accuracy: 0.5925 - val_loss: 0.8885 - val_accuracy: 0.6050\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.8859 - accuracy: 0.5950 - val_loss: 0.8843 - val_accuracy: 0.6050\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 1s 11ms/step - loss: 0.8814 - accuracy: 0.5953 - val_loss: 0.8742 - val_accuracy: 0.6062\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8810 - accuracy: 0.5950 - val_loss: 0.8795 - val_accuracy: 0.6025\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8786 - accuracy: 0.5906 - val_loss: 0.8754 - val_accuracy: 0.6050\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 1s 8ms/step - loss: 0.8766 - accuracy: 0.5953 - val_loss: 0.8861 - val_accuracy: 0.6087\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 1s 9ms/step - loss: 0.8754 - accuracy: 0.5950 - val_loss: 0.8765 - val_accuracy: 0.6037\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.8765 - accuracy: 0.6037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8765424489974976, 0.6037499904632568]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_text_bilstm = Dense(3, activation='softmax')(text_features_bilstm)\n",
    "\n",
    "# 构建文本模型\n",
    "text_model = Model(inputs=text_input_bilstm, outputs=predictions_text_bilstm)\n",
    "text_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "text_model.fit(train_text_pad, train_label_one_hot, epochs=10, batch_size=32, validation_data=(val_text_pad, val_label_one_hot))\n",
    "\n",
    "# 在验证集上评估模型\n",
    "text_model.evaluate(val_text_pad, val_label_one_hot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 消融实验4：ResNet_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 17s 120ms/step - loss: 1.6927 - accuracy: 0.5800 - val_loss: 3.0583 - val_accuracy: 0.5925\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 1.9222 - accuracy: 0.5741 - val_loss: 1.8436 - val_accuracy: 0.5987\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 1.3970 - accuracy: 0.5766 - val_loss: 12.3762 - val_accuracy: 0.5225\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 10s 96ms/step - loss: 1.3193 - accuracy: 0.5863 - val_loss: 1.0635 - val_accuracy: 0.5888\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 11s 108ms/step - loss: 1.2025 - accuracy: 0.5747 - val_loss: 0.9803 - val_accuracy: 0.6000\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 12s 121ms/step - loss: 1.0216 - accuracy: 0.5850 - val_loss: 0.9184 - val_accuracy: 0.6037\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 10s 102ms/step - loss: 1.0031 - accuracy: 0.5866 - val_loss: 0.9744 - val_accuracy: 0.5875\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 10s 104ms/step - loss: 0.9937 - accuracy: 0.5884 - val_loss: 0.9239 - val_accuracy: 0.6025\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 12s 124ms/step - loss: 0.9700 - accuracy: 0.5822 - val_loss: 2.8138 - val_accuracy: 0.5525\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 11s 110ms/step - loss: 0.9840 - accuracy: 0.5853 - val_loss: 1.0931 - val_accuracy: 0.5938\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 1.0931 - accuracy: 0.5938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0930933952331543, 0.59375]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_images_resnet = Dense(3, activation='softmax')(image_features_resnet)\n",
    "# 构建图像模型\n",
    "image_model = Model(inputs=image_input_resnet, outputs=predictions_images_resnet)\n",
    "image_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "image_model.fit(train_image, train_label_one_hot, epochs=10, batch_size=32, validation_data=(val_image, val_label_one_hot))\n",
    "\n",
    "# 在验证集上评估模型\n",
    "image_model.evaluate(val_image, val_label_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
